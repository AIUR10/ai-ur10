{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try UR10 gym env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./gym-examples/\") # to be ale to import from the gym_examples folder, which I simply put inside this project\n",
    "import gym_examples\n",
    "import gym\n",
    "from gym.wrappers import TimeLimit\n",
    "from stable_baselines3 import SAC\n",
    "import tensorboard\n",
    "from NormalizeActionWrapper import NormalizeActionWrapper\n",
    "from TensorboardCallback import TensorboardCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation time step: 0.05000000074505806 seconds\n"
     ]
    }
   ],
   "source": [
    "# If you get errors, make sure to install ROS/ROS2\n",
    "# enough for ROS : http://wiki.ros.org/ROS/Installation/TwoLineInstall/\n",
    "# (if you want to try with ROS2 install Foxy)\n",
    "# We also had to install lpeg. We did it with luarocks.\n",
    "max_episode_steps = 12000\n",
    "env = TimeLimit(NormalizeActionWrapper(gym.make('gym_examples/UR10-v0', max_steps=50, headless=False, responsive_ui=True)), max_episode_steps=max_episode_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -8.72664630e-01, -2.44346094e+00, -2.96705961e+00,\n",
       "       -1.57079637e+00,  1.57079637e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -4.36371565e-03, -4.94211912e-04, -5.82885742e-03, -5.82081079e-03,\n",
       "        2.49448419e-03,  2.54358739e-01])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAC('MlpPolicy', env, tensorboard_log=\"./sac_ur10_tensorboard/\")#, learning_rate=0.003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = SAC.load(\"logs/rl_model_100000_steps.zip\")\n",
    "#model.set_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a checkpoint every 1000 steps\n",
    "checkpoint_callback = TensorboardCallback(\n",
    "  env=env,\n",
    "  save_freq=500000,\n",
    "  save_path=\"./logs/\",\n",
    "  name_prefix=\"rl_model\",\n",
    "  save_replay_buffer=True,\n",
    "  save_vecnormalize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DummyVecEnv' object has no attribute 'distance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mdistance\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DummyVecEnv' object has no attribute 'distance'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f2f4cec66d0>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DummyVecEnv' object has no attribute 'distance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49mmax_episode_steps\u001b[39m*\u001b[39;49m\u001b[39m10000\u001b[39;49m, callback\u001b[39m=\u001b[39;49mcheckpoint_callback)\n",
      "File \u001b[0;32m~/Projets/mastere_ia/cours/IA712-Robotique_Mobile/Projet/ai-ur10/venv/lib/python3.9/site-packages/stable_baselines3/sac/sac.py:302\u001b[0m, in \u001b[0;36mSAC.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    294\u001b[0m     \u001b[39mself\u001b[39m: SelfSAC,\n\u001b[1;32m    295\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    300\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    301\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfSAC:\n\u001b[0;32m--> 302\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    303\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    304\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    305\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    306\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    307\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    308\u001b[0m         progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m    309\u001b[0m     )\n",
      "File \u001b[0;32m~/Projets/mastere_ia/cours/IA712-Robotique_Mobile/Projet/ai-ur10/venv/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:311\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    308\u001b[0m callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[1;32m    310\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 311\u001b[0m     rollout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\n\u001b[1;32m    312\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv,\n\u001b[1;32m    313\u001b[0m         train_freq\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_freq,\n\u001b[1;32m    314\u001b[0m         action_noise\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_noise,\n\u001b[1;32m    315\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    316\u001b[0m         learning_starts\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_starts,\n\u001b[1;32m    317\u001b[0m         replay_buffer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreplay_buffer,\n\u001b[1;32m    318\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    319\u001b[0m     )\n\u001b[1;32m    321\u001b[0m     \u001b[39mif\u001b[39;00m rollout\u001b[39m.\u001b[39mcontinue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    322\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Projets/mastere_ia/cours/IA712-Robotique_Mobile/Projet/ai-ur10/venv/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:551\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    549\u001b[0m callback\u001b[39m.\u001b[39mupdate_locals(\u001b[39mlocals\u001b[39m())\n\u001b[1;32m    550\u001b[0m \u001b[39m# Only stop training if return value is False, not when it is None.\u001b[39;00m\n\u001b[0;32m--> 551\u001b[0m \u001b[39mif\u001b[39;00m callback\u001b[39m.\u001b[39;49mon_step() \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m     \u001b[39mreturn\u001b[39;00m RolloutReturn(num_collected_steps \u001b[39m*\u001b[39m env\u001b[39m.\u001b[39mnum_envs, num_collected_episodes, continue_training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    554\u001b[0m \u001b[39m# Retrieve reward and episode length if using Monitor wrapper\u001b[39;00m\n",
      "File \u001b[0;32m~/Projets/mastere_ia/cours/IA712-Robotique_Mobile/Projet/ai-ur10/venv/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:104\u001b[0m, in \u001b[0;36mBaseCallback.on_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_calls \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    102\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mnum_timesteps\n\u001b[0;32m--> 104\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_on_step()\n",
      "File \u001b[0;32m~/Projets/mastere_ia/cours/IA712-Robotique_Mobile/Projet/ai-ur10/TensorboardCallback.py:13\u001b[0m, in \u001b[0;36mTensorboardCallback._on_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m# Log scalar values\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mget_env())\n\u001b[0;32m---> 13\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mrecord(\u001b[39m\"\u001b[39m\u001b[39mdistance\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_env\u001b[39m.\u001b[39;49mdistance)\n\u001b[1;32m     14\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mrecord(\u001b[39m\"\u001b[39m\u001b[39morientation_penalty\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_env\u001b[39m.\u001b[39morientation_penalty)\n\u001b[1;32m     15\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mrecord(\u001b[39m\"\u001b[39m\u001b[39morientation_coef\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_env\u001b[39m.\u001b[39morientation_coef)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DummyVecEnv' object has no attribute 'distance'"
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=max_episode_steps*10000, callback=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03246813294659552"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.sqrt(np.square(env.get_obs()[-3]) + np.square(env.get_obs()[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03652704724711853"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(env.get_obs()[-7:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"sac_circular\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_replay_buffer(\"sac_circular_replay_buffer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CoppeliaSim:loadinfo]   done.\n"
     ]
    }
   ],
   "source": [
    "env.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
